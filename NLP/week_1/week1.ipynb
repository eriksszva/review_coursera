{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lesson 1\n",
        "\n"
      ],
      "metadata": {
        "id": "bO43AZiZ_S5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tokenization sentences"
      ],
      "metadata": {
        "id": "JSjWYIhCDpOM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maXyrnav9vKm",
        "outputId": "45c2af67-5855-4218-c2c5-c5c72385a9e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[np.str_('my'), np.str_('love'), np.str_('i'), np.str_('dog'), np.str_('you'), np.str_('cat')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "sentences = [\n",
        "    'I love my dog',\n",
        "    'I, love my cat',\n",
        "    'You love my dog!'\n",
        "]\n",
        "\n",
        "# initialize the layer\n",
        "# create an instance of text vectorization layer\n",
        "vectorize_layer = tf.keras.layers.TextVectorization()\n",
        "\n",
        "# takes in the data and generates a vocabulary outta the words found in these sentences\n",
        "vectorize_layer.adapt(sentences)\n",
        "\n",
        "# view the result\n",
        "vocabulary = vectorize_layer.get_vocabulary(include_special_tokens=False)\n",
        "print(vocabulary)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* TextVectorization layer only get a vocabulary outta the words found in the sentences.\n",
        "* also lower case-ing the word.\n",
        "* TextVectorization strips out punctuations.\n",
        "`include_special_tokens=False` -> not to get empty string and [UNK] token"
      ],
      "metadata": {
        "id": "_NA7ng1PAwKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, word in enumerate(vocabulary):\n",
        "  print(idx, word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY5SEz7V_vWc",
        "outputId": "7102a129-8f39-4fcb-9a2e-99ce690c30a0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 my\n",
            "1 love\n",
            "2 i\n",
            "3 dog\n",
            "4 you\n",
            "5 cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "include the special tokens. the first one at `0` is used for padding and `1` isused for out-of-vocabulary words."
      ],
      "metadata": {
        "id": "4A3TNKo7CbsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the vocabulary list\n",
        "vocabulary = vectorize_layer.get_vocabulary()\n",
        "\n",
        "# print the token index\n",
        "for idx, word in enumerate(vocabulary):\n",
        "  print(idx, word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hr67ypNnCOmr",
        "outputId": "e76cd084-a881-481f-f651-aac7afc80b18"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 \n",
            "1 [UNK]\n",
            "2 my\n",
            "3 love\n",
            "4 i\n",
            "5 dog\n",
            "6 you\n",
            "7 cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `[PAD]` | Padding (to fill gaps so that all input sequences have the same length)\n",
        "* `[UNK]` | Unknown (used when the model encounters a word it doesn't know)\n",
        "* `[CLS]` | Classification token (used in models like BERT, marks the start of a text for classification)\n",
        "* `[SEP]` | Separator (used to separate different sentences)"
      ],
      "metadata": {
        "id": "zGEZ_dqIjoQa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why are special tokens often included?\n",
        "Because the model needs to understand when:\n",
        "\n",
        "* There are empty spaces (padding).\n",
        "* It encounters an unknown word (word not in the vocabulary).\n",
        "* It needs to separate or classify sentences.\n",
        "\n",
        "If special tokens are missing:\n",
        "\n",
        "* The model might get confused when input sequences have different lengths.\n",
        "* It won't know how to handle unknown words.\n",
        "\n",
        "If special tokens are included:\n",
        "\n",
        "* It can fill empty spaces using [PAD].\n",
        "* It can replace unknown words with [UNK].\n",
        "* It can mark the beginning of sentences with [CLS] (for classification tasks).\n"
      ],
      "metadata": {
        "id": "aVlMwPpxj9XL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lesson 2\n",
        "\n",
        "* add another sentences, so the sentence will a bit longer than the others.\n",
        "* will demonstrate padding."
      ],
      "metadata": {
        "id": "lLlUTAW9Dt-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## encoding"
      ],
      "metadata": {
        "id": "ifJeOlNyFy25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    'I love my dog',\n",
        "    'I, love my cat',\n",
        "    'You love my dog!',\n",
        "    'Do you think my dog is amazing?'\n",
        "]\n",
        "\n",
        "# initialize the layer\n",
        "# create an instance of text vectorization layer\n",
        "vectorize_layer = tf.keras.layers.TextVectorization()\n",
        "\n",
        "# takes in the data and generates a vocabulary outta the words found in these sentences\n",
        "vectorize_layer.adapt(sentences)\n",
        "\n",
        "# view the result\n",
        "vocabulary = vectorize_layer.get_vocabulary()\n",
        "\n",
        "sequence = vectorize_layer('I love my dog')\n",
        "\n",
        "for idx, word in enumerate(vocabulary):\n",
        "  print(idx, word)\n",
        "\n",
        "print()\n",
        "print(sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AHM0T9QDQsy",
        "outputId": "f92a28b3-d0ed-486d-be4e-df66fb79a54b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 \n",
            "1 [UNK]\n",
            "2 my\n",
            "3 love\n",
            "4 dog\n",
            "5 you\n",
            "6 i\n",
            "7 think\n",
            "8 is\n",
            "9 do\n",
            "10 cat\n",
            "11 amazing\n",
            "\n",
            "tf.Tensor([6 3 2 4], shape=(4,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence2 = vectorize_layer(sentences)\n",
        "print(sequence2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZrt0kOYD8kE",
        "outputId": "8764eb79-b754-4882-b2f4-2fe7d2728e01"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 6  3  2  4  0  0  0]\n",
            " [ 6  3  2 10  0  0  0]\n",
            " [ 5  3  2  4  0  0  0]\n",
            " [ 9  5  7  2  4  8 11]], shape=(4, 7), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* vectorize_layer.adapt() -> give the tokenization.\n",
        "* vectorize_layer() -> give the encoding.\n",
        "* 0 -> padding: to make all of this in the same length as the last row\n",
        "* post padding -> the padding tokens at the end of the sequences."
      ],
      "metadata": {
        "id": "lbgh7Ju1FJWm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## padding"
      ],
      "metadata": {
        "id": "GM-JrxB3F2i9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* this case to handle many texts\n",
        "* more scalable than `vectorize_layer()`"
      ],
      "metadata": {
        "id": "j3Muv-N-IdaM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pre-padding for small dataset using tf data pipeline"
      ],
      "metadata": {
        "id": "BW2ksyMfhkno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize TextVectorization\n",
        "vectorize_layer = tf.keras.layers.TextVectorization()\n",
        "\n",
        "# get tokenization\n",
        "vectorize_layer.adapt(sentences)\n",
        "vocabulary = vectorize_layer.get_vocabulary()\n",
        "\n",
        "sentences_dataset = tf.data.Dataset.from_tensor_slices(sentences)\n",
        "sequences = sentences_dataset.map(vectorize_layer)\n",
        "sequences_pre = tf.keras.utils.pad_sequences(sequences, padding='pre')\n",
        "print(sequences_pre)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keTm785bFHvf",
        "outputId": "59b8dc18-f0e6-4e0f-8f3d-3b1752b1c6a1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  6  3  2  4]\n",
            " [ 0  0  0  6  3  2 10]\n",
            " [ 0  0  0  5  3  2  4]\n",
            " [ 9  5  7  2  4  8 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence, sequence in zip(sentences, sequences):\n",
        "  print(f'{sentences} -> {sequence}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN_Pg-KmHfYP",
        "outputId": "73b9cc2a-270d-45d7-bb3d-9fc7d36d36d5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I love my dog', 'I love my cat', 'You love my dog', 'Do you think my dog is amazing?'] -> [6 3 2 4]\n",
            "['I love my dog', 'I love my cat', 'You love my dog', 'Do you think my dog is amazing?'] -> [ 6  3  2 10]\n",
            "['I love my dog', 'I love my cat', 'You love my dog', 'Do you think my dog is amazing?'] -> [5 3 2 4]\n",
            "['I love my dog', 'I love my cat', 'You love my dog', 'Do you think my dog is amazing?'] -> [ 9  5  7  2  4  8 11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### padding with limitation\n"
      ],
      "metadata": {
        "id": "ocEi7HhYWAmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences_post_trunc = tf.keras.utils.pad_sequences(sequences,\n",
        "                                                    maxlen=5,\n",
        "                                                    padding='pre')\n",
        "\n",
        "print('INPUT:')\n",
        "# if print the sequence directly it'll return to be\n",
        "# [<tf.Tensor: shape=(4,), dtype=int64, numpy=array([6, 3, 2, 4])>, ... ]\n",
        "[print(sequence.numpy()) for sequence in sequences]\n",
        "print()\n",
        "\n",
        "print('OUTPUT:')\n",
        "print(sequences_post_trunc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oiooljZWDPb",
        "outputId": "6fc7c338-ca2c-4b7c-9f0e-bb48eba04d7d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT:\n",
            "[6 3 2 4]\n",
            "[ 6  3  2 10]\n",
            "[5 3 2 4]\n",
            "[ 9  5  7  2  4  8 11]\n",
            "\n",
            "OUTPUT:\n",
            "[[ 0  6  3  2  4]\n",
            " [ 0  6  3  2 10]\n",
            " [ 0  5  3  2  4]\n",
            " [ 7  2  4  8 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### keep the real text without padding"
      ],
      "metadata": {
        "id": "CHDGayeJQhra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize TextVectorization\n",
        "vectorize_layer = tf.keras.layers.TextVectorization(ragged=True)\n",
        "\n",
        "# get tokenization\n",
        "vectorize_layer.adapt(sentences)\n",
        "vocabulary = vectorize_layer.get_vocabulary()\n",
        "\n",
        "# encoded outputs\n",
        "ragged_sequences = vectorize_layer(sentences)\n",
        "for idx, word in enumerate(vocabulary):\n",
        "  print(idx, word)\n",
        "print()\n",
        "print(ragged_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PS-Gd5LHHgbT",
        "outputId": "da671f7a-a730-4e2e-e9a6-2e00e4a0a0e5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 \n",
            "1 [UNK]\n",
            "2 my\n",
            "3 love\n",
            "4 dog\n",
            "5 you\n",
            "6 i\n",
            "7 think\n",
            "8 is\n",
            "9 do\n",
            "10 cat\n",
            "11 amazing\n",
            "\n",
            "<tf.RaggedTensor [[6, 3, 2, 4], [6, 3, 2, 10], [5, 3, 2, 4], [9, 5, 7, 2, 4, 8, 11]]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* longer sequences will be truncated"
      ],
      "metadata": {
        "id": "oXxllLYvWozp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## whp when meet new data in test set"
      ],
      "metadata": {
        "id": "lww93axmRvyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    'I love my dog',\n",
        "    'I love my cat',\n",
        "    'You love my dog',\n",
        "    'Do you think my dog is amazing?'\n",
        "]\n",
        "\n",
        "vectorize_layer = tf.keras.layers.TextVectorization()\n",
        "vectorize_layer.adapt(sentences)\n",
        "\n",
        "test_data = [\n",
        "    'i really love my dog',\n",
        "    'my dog loves my manatee'\n",
        "]\n",
        "\n",
        "test_seq = vectorize_layer(test_data)\n",
        "print(test_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62ibgHpXRI7q",
        "outputId": "b3e9a72c-dffc-4cab-c5ca-f49e29f49b2b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[6 1 3 2 4]\n",
            " [2 4 1 2 1]], shape=(2, 5), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, word in enumerate(vocabulary):\n",
        "  print(idx, word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6ATjtTgT3Zh",
        "outputId": "d2fa01f3-adba-4d1b-8a84-f8941b91ee84"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 \n",
            "1 [UNK]\n",
            "2 my\n",
            "3 love\n",
            "4 dog\n",
            "5 you\n",
            "6 i\n",
            "7 think\n",
            "8 is\n",
            "9 do\n",
            "10 cat\n",
            "11 amazing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* since the vocabulary doesn't have some other words, it can't handle the new word (it's writen to be 1, if it's new word)"
      ],
      "metadata": {
        "id": "2cJdZVttS9Nk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lesson 3\n",
        "\n"
      ],
      "metadata": {
        "id": "YVd7AR7wX0pt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizing the sarcasm dataset"
      ],
      "metadata": {
        "id": "Fm9jOEXZhPnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# open the file\n",
        "with open('sarcasm.json', 'r') as f:\n",
        "  datastore = json.load(f)"
      ],
      "metadata": {
        "id": "Ftirf7J4avEc"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datastore[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwAXNsnNYaMj",
        "outputId": "29e3dff9-0743-47a2-a74c-f7e9cce854a3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'article_link': 'https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5',\n",
              "  'headline': \"former versace store clerk sues over secret 'black code' for minority shoppers\",\n",
              "  'is_sarcastic': 0},\n",
              " {'article_link': 'https://www.huffingtonpost.com/entry/roseanne-revival-review_us_5ab3a497e4b054d118e04365',\n",
              "  'headline': \"the 'roseanne' revival catches up to our thorny political mood, for better and worse\",\n",
              "  'is_sarcastic': 0}]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* datastore is list of dictionaries\n",
        "* make each key to be list. sentences needed for training, labels as the ground truth, and link to check sources not needed in the modeling."
      ],
      "metadata": {
        "id": "-W11Qtb-YfpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# append the headline elements into the list\n",
        "sentences = [item['headline'] for item in datastore]"
      ],
      "metadata": {
        "id": "zou7L3-fT26j"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print a sample headline and sequence\n",
        "index = 2\n",
        "print(f'sample headline: {sentences[index]}')\n",
        "print(f'padded sequence: {post_padded_sequences[index]}')\n",
        "print()\n",
        "\n",
        "# print dimensions of padded sequences\n",
        "print(f'shape of padded sequences: {post_padded_sequences.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-9apy-yYa_7",
        "outputId": "15fa5939-e792-43ba-84ae-5d0c5c40aed8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample headline: mom starting to fear son's web series closest thing she will have to grandchild\n",
            "padded sequence: [  140   825     2   813  1100  2048   571  5057   199   139    39    46\n",
            "     2 13050     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0]\n",
            "\n",
            "shape of padded sequences: (26709, 39)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "vectorize_layer = tf.keras.layers.TextVectorization()\n",
        "vectorize_layer.adapt(sentences)\n",
        "\n",
        "vocabulary = vectorize_layer.get_vocabulary()\n",
        "post_padded_sequences = vectorize_layer(sentences)\n",
        "print(f'padded sequence: {post_padded_sequences[2]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxlylmhSZXkq",
        "outputId": "c400ec40-f8db-4049-c42c-5c44e3ef3371"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "padded sequence: [  140   825     2   813  1100  2048   571  5057   199   139    39    46\n",
            "     2 13050     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pre-padding for large dataset concept"
      ],
      "metadata": {
        "id": "iuOM8xnsdG0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instiate the layer and set the ragged to be `True`\n",
        "vectorize_layer = tf.keras.layers.TextVectorization(ragged=True)\n",
        "\n",
        "# build the vocabulary\n",
        "vectorize_layer.adapt(sentences)"
      ],
      "metadata": {
        "id": "A5GfOzw0dKmR"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the layer to generate a ragged tensor\n",
        "ragged_sequences = vectorize_layer(sentences)"
      ],
      "metadata": {
        "id": "po7b_ItldaHn"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print a sample headline and sequence\n",
        "index = 2\n",
        "print(f'sample headline: {sentences[index]}')\n",
        "print(f'padded sequence: {ragged_sequences[index]}')\n",
        "print()\n",
        "\n",
        "# print dimensions of padded sequences\n",
        "print(f'shape of padded sequences: {ragged_sequences.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOSx5KwVfIaf",
        "outputId": "420aed6b-5984-44c0-de28-45423b870a09"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample headline: mom starting to fear son's web series closest thing she will have to grandchild\n",
            "padded sequence: [  140   825     2   813  1100  2048   571  5057   199   139    39    46\n",
            "     2 13050]\n",
            "\n",
            "shape of padded sequences: (26709, None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* no padded part\n",
        "* `(26709, None)` previously 39 and now `None` indicates no longer post padded to the max length."
      ],
      "metadata": {
        "id": "2qV_hGYUfj0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ragged_sequences.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUP6W-3IgUT9",
        "outputId": "aeaa4780-7722-4a25-cf0a-1156dac2d603"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tf.int64"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply pre-padding to the ragged tensor\n",
        "pre_padded_sequences = tf.keras.utils.pad_sequences(ragged_sequences.numpy())\n",
        "\n",
        "# preview the result for the 2nd sequence\n",
        "pre_padded_sequences[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOupWGcyf7v2",
        "outputId": "4c6119e8-2c01-4390-f557-d3e3eda74573"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,   140,   825,\n",
              "           2,   813,  1100,  2048,   571,  5057,   199,   139,    39,\n",
              "          46,     2, 13050], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print a sample headline and sequence\n",
        "index = 2\n",
        "print(f'sample headline: {sentences[index]}')\n",
        "print(f'padded sequence: {post_padded_sequences[index]}')\n",
        "print()\n",
        "print(f'padded sequence: {pre_padded_sequences[index]}')\n",
        "print()\n",
        "\n",
        "# print dimensions of padded sequences\n",
        "print(f'shape of post-padded sequences: {post_padded_sequences.shape}')\n",
        "print(f'shape of pre-padded sequences: {pre_padded_sequences.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAIYXyfAgZ6f",
        "outputId": "f65a40a3-ad2c-47bd-85a9-c712fca618a0"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample headline: mom starting to fear son's web series closest thing she will have to grandchild\n",
            "padded sequence: [  140   825     2   813  1100  2048   571  5057   199   139    39    46\n",
            "     2 13050     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0]\n",
            "\n",
            "padded sequence: [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0   140   825     2   813  1100  2048   571  5057   199   139    39\n",
            "    46     2 13050]\n",
            "\n",
            "shape of post-padded sequences: (26709, 39)\n",
            "shape of pre-padded sequences: (26709, 39)\n"
          ]
        }
      ]
    }
  ]
}